{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utilis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mimport\u001b[39;00m count\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutilis\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlogger\u001b[39;00m \u001b[39mimport\u001b[39;00m set_log_file\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utilis'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "import gym\n",
    "from itertools import count\n",
    "import torch\n",
    "from utilis import *\n",
    "from logger import set_log_file\n",
    "import logging\n",
    "import argparse\n",
    "from torch.distributions import Categorical\n",
    "from agent.DQN_Agent import DQN\n",
    "from agent.DQN_ensemble_Agent import DQN_ensemble\n",
    "from agent.model_1_AI import model_1_AI\n",
    "from agent.PPO_agent import PPO\n",
    "from agent.R_uncertainty_Agent import R_uncertainty\n",
    "from agent.SAC_Agent import SAC\n",
    "import gym_maze\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"|model|env|\")\n",
    "parser.add_argument(\n",
    "    \"--model\",\n",
    "    default=\"bootstrap_DQN\",\n",
    "    help=\"SAC|DQN|PPO|ensemble_DQN|bootstrap_DQN|model_1_AI|model_1_AI_actor|R_uncertainty\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--env\",\n",
    "    default=\"MountainCar-v0\",\n",
    "    help=\"maze-sample-5x5|maze-random-10x10-v0|MountainCarContinuous-v0|CartPole-v1|MountainCar-v0|LunarLander-v2|Acrobot-v1|Pendulum-v1|ALE/Breakout-v5|ALE/MontezumaRevenge-v5|MinAtar/Breakout-v0|MinAtar/Freeway-v1|maze2d-open-v0\",\n",
    ")\n",
    "parser.add_argument(\"--BATCH_SIZE\", type=int, default=64)\n",
    "parser.add_argument(\"--NUM_episodes\", type=int, default=20000)\n",
    "parser.add_argument(\"--GAMMA\", default=0.99)\n",
    "parser.add_argument(\"--TAU\", default=0.005)\n",
    "parser.add_argument(\"--PRINT\", default=False)\n",
    "parser.add_argument(\"--render\", default=0, type=int)\n",
    "parser.add_argument(\"--device\", default=\"cpu\")\n",
    "parser.add_argument(\"--prior\", default=0, type=float)\n",
    "parser.add_argument(\"--prior_noise\", default=0, type=float)\n",
    "parser.add_argument(\"--NUM_ensemble\", default=5)\n",
    "parser.add_argument(\"--ID\", default=\"DEBUG\")\n",
    "parser.add_argument(\"--foot_record\", default=False)\n",
    "parser.add_argument(\"--max_steps\", type=int, default=2e5)\n",
    "parser.add_argument(\"--repeat_average\", type=int, default=3)\n",
    "parser.add_argument(\"--eval_intervel\", type=int, default=10)\n",
    "parser.add_argument(\"--eval\", type=int, default=0)\n",
    "parser.add_argument(\"--OLD_GYM\", type=int, default=0)\n",
    "parser.add_argument(\"--no_truncated\", type=int, default=0)\n",
    "parser.add_argument(\"--update_intervel\", type=int, default=1)\n",
    "parser.add_argument(\"--real_bootstrap\", type=int, default=0)\n",
    "parser.add_argument(\"--p_net\", type=int, default=0)\n",
    "parser.add_argument(\"--DP_init\", type=int, default=0)\n",
    "parser.add_argument(\"--A_Change\", type=int, default=0)\n",
    "parser.add_argument(\"--var_net\", type=int, default=0)\n",
    "\n",
    "args = parser.parse_args()\n",
    "if args.OLD_GYM:\n",
    "    import d4rl\n",
    "if args.env.find(\"/\") > -1:\n",
    "    args.CNN = True\n",
    "else:\n",
    "    args.CNN = False\n",
    "envstr = args.env.split(\"/\")[-1]\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "# config the args\n",
    "# set the log file\n",
    "config = f\"{args.model}_{envstr}_prior{args.prior}_std{args.prior_noise}_{args.ID}\"\n",
    "print(\"###########################\")\n",
    "print(\"###########################\")\n",
    "print(\"trainning start: \", config)\n",
    "print(\"###########################\")\n",
    "print(\"###########################\")\n",
    "set_log_file(f\"log/{config}.txt\")\n",
    "writer = SummaryWriter(f\"runs/{envstr}/{config}\")\n",
    "# set env\n",
    "env = gym.make(args.env)\n",
    "if (not args.OLD_GYM) and args.render:\n",
    "    env = gym.make(args.env, render_mode=\"human\")\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "if args.OLD_GYM:\n",
    "    state = env.reset()\n",
    "else:\n",
    "    state, info = env.reset()\n",
    "\n",
    "state_shape = state.shape\n",
    "# set device\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# set the model\n",
    "if args.model == \"DQN\":\n",
    "    agent = DQN(\n",
    "        state_shape,\n",
    "        n_actions,\n",
    "        env,\n",
    "        args.CNN,\n",
    "        GAMMA=args.GAMMA,\n",
    "        BATCH_SIZE=args.BATCH_SIZE,\n",
    "        prior=args.prior,\n",
    "    )\n",
    "elif args.model == \"PPO\":\n",
    "    agent = PPO(state_shape, n_actions, env, writer, prior=args.prior)\n",
    "elif args.model == \"ensemble_DQN\":\n",
    "    agent = DQN_ensemble(\n",
    "        env,\n",
    "        args.NUM_ensemble,\n",
    "        state_shape,\n",
    "        n_actions,\n",
    "        writer,\n",
    "        args.CNN,\n",
    "        GAMMA=args.GAMMA,\n",
    "        BATCH_SIZE=args.BATCH_SIZE,\n",
    "        prior=args.prior,\n",
    "        prior_noise=args.prior_noise,\n",
    "        p_net=args.p_net,\n",
    "    )\n",
    "elif args.model == \"bootstrap_DQN\":\n",
    "    agent = DQN_ensemble(\n",
    "        env,\n",
    "        args.NUM_ensemble,\n",
    "        state_shape,\n",
    "        n_actions,\n",
    "        writer,\n",
    "        args.CNN,\n",
    "        GAMMA=args.GAMMA,\n",
    "        BATCH_SIZE=args.BATCH_SIZE,\n",
    "        bootstrap=True,\n",
    "        prior=args.prior,\n",
    "        prior_noise=args.prior_noise,\n",
    "        DP_init=args.DP_init,\n",
    "        real_bootstrap=args.real_bootstrap,\n",
    "        A_change=args.A_Change,\n",
    "        var_net_flag=args.var_net,\n",
    "    )\n",
    "elif args.model == \"model_1_AI\":\n",
    "    agent = model_1_AI(args.NUM_ensemble, state_shape, n_actions)\n",
    "elif args.model == \"SAC\":\n",
    "    agent = SAC(state_shape, n_actions)\n",
    "elif args.model == \"R_uncertainty\":\n",
    "    agent = R_uncertainty(\n",
    "        state_shape,\n",
    "        n_actions,\n",
    "        writer,\n",
    "        env,\n",
    "        args.CNN,\n",
    "        GAMMA=args.GAMMA,\n",
    "        BATCH_SIZE=args.BATCH_SIZE,\n",
    "        TAU=args.TAU,\n",
    "        prior=args.prior,\n",
    "    )\n",
    "##########################################################################################################\n",
    "\n",
    "steps_done = 0\n",
    "if __name__ == \"__main__\":\n",
    "    cum_R = []\n",
    "    steps_episode = []\n",
    "    for i_episode in range(args.NUM_episodes):\n",
    "        # Initialize the environment and get it's state\n",
    "        if args.OLD_GYM:\n",
    "            state = env.reset()\n",
    "            if args.render:\n",
    "                env.render()\n",
    "        else:\n",
    "            state, info = env.reset()\n",
    "        state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        E_count = 0\n",
    "        cum_R_float = 0\n",
    "        if steps_done > args.max_steps:\n",
    "            break\n",
    "\n",
    "        for t in count():\n",
    "            steps_done += 1\n",
    "            if args.foot_record:\n",
    "                if steps_done < 20000:\n",
    "                    logging.info(f\"foot: {state[0,0].item()} {state[0,1].item()}\")\n",
    "            # select action accroding to Free energy\n",
    "\n",
    "            action, E, action_prob = agent.select_action(state)\n",
    "            # count the explore step number\n",
    "            E_count += E\n",
    "            # step forward\n",
    "            truncated = False\n",
    "            if args.OLD_GYM:\n",
    "                observation, reward, terminated, _ = env.step(action.item())\n",
    "                if args.render:\n",
    "                    env.render()\n",
    "            else:\n",
    "                observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "            cum_R_float += reward\n",
    "\n",
    "            reward = torch.tensor([reward])\n",
    "            terminated = torch.tensor([terminated], dtype=torch.float32)\n",
    "            action_prob = torch.tensor([action_prob], dtype=torch.float32)\n",
    "\n",
    "            if args.env == \"MountainCar-v0\":\n",
    "                if t == 999:\n",
    "                    truncated = True\n",
    "                else:\n",
    "                    truncated = False\n",
    "            if args.no_truncated:\n",
    "                truncated = False\n",
    "            done = terminated or truncated\n",
    "\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            # Store the transition in memory\n",
    "            agent.buffer.push(\n",
    "                state, action, action_prob, next_state, reward, terminated\n",
    "            )\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # update the network\n",
    "            if steps_done % args.update_intervel == 0:\n",
    "                agent.update()\n",
    "\n",
    "            # if steps_done % 100 == 0:\n",
    "            #     getRM(model=agent.Ensemble_Q_net,plot=False)\n",
    "            #     getRM_mean(model=agent.Ensemble_Q_net,plot=False)\n",
    "\n",
    "            if done:\n",
    "                if i_episode % args.eval_intervel == 0 and args.eval == True:\n",
    "                    eva_cum_R = evaluate(env, agent, repeat_average=args.repeat_average)\n",
    "                    print(\n",
    "                        f\"{i_episode}, evaluate cum R: {eva_cum_R}, Total_steps: {steps_done}\"\n",
    "                    )\n",
    "                    writer.add_scalar(\"eva cum R of steps\", eva_cum_R, steps_done)\n",
    "                    writer.add_scalar(\"eva cum R of episode\", eva_cum_R, i_episode)\n",
    "                msg = f\" {i_episode}  R: {cum_R_float} step: {t+1}  E: {E_count/(t+1)}  Total_steps: {steps_done}\"\n",
    "                print(msg)\n",
    "                logging.info(msg)\n",
    "                cum_R.append(t + 1)\n",
    "                steps_episode.append(steps_done)\n",
    "                writer.add_scalar(\"cum R of episode\", cum_R_float, i_episode)\n",
    "                writer.add_scalar(\"cum R of steps\", cum_R_float, steps_done)\n",
    "                writer.add_scalar(\"E rate\", E_count / (t + 1), i_episode)\n",
    "                agent.buffer.save_cum_R(cum_R_float)\n",
    "                break\n",
    "\n",
    "    print(f\"Complete: {config}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
